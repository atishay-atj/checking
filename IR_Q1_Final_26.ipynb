{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVub4zm1op_x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/IR_ASSIGNMENT_FINAL/CSE508_Winter2023_Dataset'\n",
        "\n",
        "# Initialize a counter variable\n",
        "count = 0\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    with open(file_path, 'r') as file:\n",
        "        contents = file.read()\n",
        "\n",
        "    start_title = contents.find(\"<TITLE>\")+len(\"<TITLE>\")\n",
        "    end_title = contents.find(\"</TITLE>\")\n",
        "    title = contents[start_title:end_title].strip()\n",
        "\n",
        "    start_text = contents.find(\"<TEXT>\") + len(\"<TEXT>\")\n",
        "    end_text = contents.find(\"</TEXT>\")\n",
        "    text = contents[start_text:end_text].strip()    \n",
        "    new_content = title + \" \" + text\n",
        "\n",
        "    # Check if we have processed less than 5 files\n",
        "    if count < 5:\n",
        "        print(f\"Contents of file {filename} before:\\n{contents}\\n\")\n",
        "        print(f\"Contents of file {filename} after:\\n{new_content}\\n\")\n",
        "        \n",
        "    # Increment the counter variable\n",
        "    count += 1\n",
        "\n",
        "    # Write the modified contents back to the file\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(new_content)\n",
        "        \n",
        "    # Check if we have processed 5 files, and break out of the loop if we have\n",
        "    if count == 5:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Initialize a counter variable\n",
        "count = [0]\n",
        "\n",
        "def preprocess_text(text, count, filename):\n",
        "    # Increment the count\n",
        "    count[0] += 1\n",
        "\n",
        "    # Convert the text to lowercase\n",
        "    if count[0] <= 5:\n",
        "        print(f\"Contents of file {filename} before Lowercasing the text:\\n{text}\\n\")\n",
        "    text = text.lower()\n",
        "    if count[0] <= 5:\n",
        "        print(f\"Contents of file {filename} after Lowercasing the text:\\n{text}\\n\")\n",
        "\n",
        "    # Tokenize the text\n",
        "    if count[0] <= 5:\n",
        "        print(f\"Contents of file {filename} before Performing tokenization:\\n{text}\\n\")\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    if count[0] <= 5:\n",
        "        print(f\"Contents of file {filename} after Performing tokenization:\\n{tokens}\\n\")\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = nltk.corpus.stopwords.words('english')\n",
        "    if count[0] <= 5:\n",
        "        print(f\"Contents of file {filename} before Removing stopwords:\\n{tokens}\\n\")\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    if count[0] <= 5:\n",
        "        print(f\"Contents of file {filename} after Removing stopwords:\\n{tokens}\\n\")\n",
        "\n",
        "    # Remove punctuations\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    if count[0] <= 5:\n",
        "        print(f\"Contents of file {filename} before Removing punctuations:\\n{tokens}\\n\")\n",
        "    tokens = [token.translate(table) for token in tokens]\n",
        "    if count[0] <= 5:\n",
        "        print(f\"Contents of file {filename} after Removing punctuations:\\n{tokens}\\n\")\n",
        "\n",
        "    # Remove blank space tokens\n",
        "    if count[0] <= 5:\n",
        "        print(f\"Contents of file {filename} before Removing blank space tokens:\\n{tokens}\\n\")\n",
        "    tokens = list(filter(lambda x: x.strip(), tokens))\n",
        "    if count[0] <= 5:\n",
        "        print(f\"Contents of file {filename} after Removing blank space tokens:\\n{tokens}\\n\")\n",
        "\n",
        "    return tokens\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/IR_ASSIGNMENT_FINAL/CSE508_Winter2023_Dataset'\n",
        "for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    tokens = preprocess_text(text, count, filename)\n",
        "    #convert list to string using (list comprehension)\n",
        "    listToStr = ' '.join([str(elem) for elem in tokens]) \n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(listToStr)"
      ],
      "metadata": {
        "id": "__iiLV8Po5Na"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}